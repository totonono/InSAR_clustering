{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Preparing Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import percentile\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn as sns; sns.set(font_scale=1.2) \n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import DBSCAN\n",
    "import hdbscan\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "AD6=pd.read_csv(\"C:/599_Research/FINAL_RESEARCH_and_PPT/THESIS_SUBMISSION/APPENDIX/2_SINGLE ATTRIBUTE SCRIPTS/DATA/AD6.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2 : Pre-processing & Execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect - example on df asc south\n",
    "AD6.head()\n",
    "AD6.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the data for the CUMULATIVE (OR ANY OTHER ATTRIBUTE), changing the hue allows you to visualize any attribute\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.scatter(AD6['LONG'],AD6['LAT'], c= AD6['D20200131'], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###specific to GMM!\n",
    "#GMM\n",
    "#the Akaike information criterion (AIC) or the Bayesian information criterion (BIC).\n",
    "X = np.array(list(zip(AD6['D20190125'],AD6['D20200131'])))\n",
    "n_components = np.arange(1, 21)\n",
    "models = [GMM(n, covariance_type='full', random_state=0).fit(X) for n in n_components]\n",
    "plt.plot(n_components, [m.bic(X) for m in models], label='BIC')\n",
    "plt.plot(n_components, [m.aic(X) for m in models], label='AIC')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('n_components');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelBest(arr:list, X:int)->list:\n",
    "    '''\n",
    "    returns the set of X configurations with shorter distance\n",
    "    '''\n",
    "    dx=np.argsort(arr)[:X]\n",
    "    return arr[dx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Silhouette Score\n",
    "X = np.array(list(zip(AD6['D20190125'],AD6['D20200131'])))\n",
    "n_clusters=np.arange(2, 20)\n",
    "sils=[]\n",
    "sils_err=[]\n",
    "iterations=20\n",
    "for n in n_clusters:\n",
    "    tmp_sil=[]\n",
    "    for _ in range(iterations):\n",
    "        gmm=GMM(n, n_init=2).fit(X) \n",
    "        labels=gmm.predict(X)\n",
    "        sil=metrics.silhouette_score(X, labels, metric='euclidean')\n",
    "        tmp_sil.append(sil)\n",
    "    val=np.mean(SelBest(np.array(tmp_sil), int(iterations/5)))\n",
    "    err=np.std(tmp_sil)\n",
    "    sils.append(val)\n",
    "    sils_err.append(err)\n",
    "    \n",
    "plt.errorbar(n_clusters, sils, yerr=sils_err)\n",
    "plt.title(\"Silhouette Scores\", fontsize=20)\n",
    "plt.xticks(n_clusters)\n",
    "plt.xlabel(\"N. of clusters\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans\n",
    "# define dataset\n",
    "X = np.array(list(zip(AD6['D20190125'],AD6['D20200131'])))\n",
    "# define the model & fit the model\n",
    "kmeans_model = KMeans(n_clusters=6, random_state=1).fit(X)\n",
    "# assign a cluster to each example\n",
    "yhat = kmeans_model.predict(X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# All the program statements\n",
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "\n",
    "print(\"Program Executed in \"+str(execution_time)) # It returns time in seconds\n",
    "\n",
    "#map the labels to colors\n",
    "c= ['b', 'r', 'y', 'g', 'c', 'm', 'e','f', 'u', 'd', 'a', 'h', 'i', 'j', 'k', 'l','n','o','p']\n",
    "colors = [c[i] for i in yhat]\n",
    "\n",
    "#Plot clusters with coordinates\n",
    "figure(num=None, figsize=(10, 8), dpi=100, facecolor='w', edgecolor='k')\n",
    "pyplot.scatter(AD6['LONG'], AD6['LAT'], c=yhat, s=10, cmap='viridis')\n",
    "plt.savefig('AD6_kmeans_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agglomerative\n",
    "#define dataset\n",
    "X = np.array(list(zip(AD6['D20190125'],AD6['D20200131'])))\n",
    "# define the model\n",
    "AGGLO_model = AgglomerativeClustering(n_clusters=6)\n",
    "# fit model and predict clusters\n",
    "yhat = AGGLO_model.fit_predict(X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# All the program statements\n",
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "\n",
    "print(\"Program Executed in \"+str(execution_time)) # It returns time in seconds\n",
    "\n",
    "#map the labels to colors\n",
    "c= ['b', 'r', 'y', 'g', 'c', 'm', 'e','f', 'u', 'd', 'a', 'h']\n",
    "colors = [c[i] for i in yhat]\n",
    "\n",
    "#Plot clusters with coordinates\n",
    "figure(num=None, figsize=(10, 8), dpi=100, facecolor='w', edgecolor='k')\n",
    "pyplot.scatter(AD6['LONG'], AD6['LAT'], c=yhat, s=10, cmap='viridis')\n",
    "plt.savefig('AD6_AGLO_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIRCH\n",
    "X = np.array(list(zip(AD6['D20190125'],AD6['D20200131'])))\n",
    "# define the model\n",
    "Birch_model = Birch(threshold = 0.8, n_clusters=6)\n",
    "# fit the model\n",
    "Birch_model.fit(X)\n",
    "# assign a cluster to each example\n",
    "yhat = Birch_model.predict(X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# All the program statements\n",
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "\n",
    "print(\"Program Executed in \"+str(execution_time)) # It returns time in seconds\n",
    "\n",
    "#map the labels to colors\n",
    "c= ['b', 'r', 'y', 'g', 'c', 'm', 'e','f', 'u', 'd', 'a', 'h']\n",
    "colors = [c[i] for i in yhat]\n",
    "\n",
    "#Plot clusters with coordinates\n",
    "figure(num=None, figsize=(10, 8), dpi=100, facecolor='w', edgecolor='k')\n",
    "pyplot.scatter(AD6['LONG'], AD6['LAT'], c=yhat, s=10, cmap='viridis')\n",
    "plt.savefig('AD6_BIRCH_t0.8_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN\n",
    "# define dataset\n",
    "X = np.array(list(zip(AD6['D20190125'],AD6['D20200131'])))\n",
    "# define the model and fit model\n",
    "DBSCAN_model = DBSCAN(eps=0.01, min_samples=6).fit(X)\n",
    "core_samples_mask = np.zeros_like(DBSCAN_model.labels_, dtype=bool)\n",
    "core_samples_mask[DBSCAN_model.core_sample_indices_] = True\n",
    "# retrieve unique clusters\n",
    "clusters = unique(DBSCAN_model)\n",
    "labels = DBSCAN_model.labels_\n",
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# All the program statements\n",
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "\n",
    "print(\"Program Executed in \"+str(execution_time)) # It returns time in seconds\n",
    "\n",
    "#Plot clusters with coordinates\n",
    "figure(num=None, figsize=(9, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.scatter(AD6['LONG'], AD6['LAT'], c=labels, s=10, cmap='plasma')\n",
    "pyplot.xlabel(\"LAT\")\n",
    "pyplot.ylabel(\"LONG\")\n",
    "plt.savefig('AD6_DBSCAN_eps0.01_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GMM\n",
    "# define dataset\n",
    "X = np.array(list(zip(AD6['D20190125'],AD6['D20200131'])))\n",
    "# define the model\n",
    "GMM_model = GMM(n_components=6)\n",
    "# fit the model\n",
    "GMM_model.fit(X)\n",
    "# assign a cluster to each example\n",
    "yhat = GMM_model.predict(X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# All the program statements\n",
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "\n",
    "print(\"Program Executed in \"+str(execution_time)) # It returns time in seconds\n",
    "\n",
    "#map the labels to colors\n",
    "c= ['b', 'r', 'y', 'g', 'c', 'm', 'e','f', 'u', 'd', 'a', 'h']\n",
    "colors = [c[i] for i in yhat]\n",
    "\n",
    "#Plot clusters with coordinates\n",
    "figure(num=None, figsize=(10, 8), dpi=100, facecolor='w', edgecolor='k')\n",
    "pyplot.scatter(AD6['LONG'], AD6['LAT'], c=yhat, s=10, cmap='viridis')\n",
    "plt.savefig('AD6_GMM_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HDBSCAN\n",
    "# cluster the data into min distance 50(what)\n",
    "X = np.array(list(zip(AD6['D20190125'],AD6['D20200131'])))\n",
    "HDBSCAN_model = hdbscan.HDBSCAN(algorithm='best', alpha=1.0, approx_min_span_tree=False,\n",
    "    gen_min_span_tree=True, leaf_size=5,\n",
    "    metric='euclidean', min_cluster_size=1200, min_samples= 20, p=None).fit(X)\n",
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# All the program statements\n",
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "\n",
    "print(\"Program Executed in \"+str(execution_time)) # It returns time in seconds\n",
    "\n",
    "\n",
    "color_palette = sns.color_palette('deep', 8)\n",
    "clusters_colors = [color_palette[x] if x >= 0\n",
    "                 else (0.5, 0.5, 0.5)\n",
    "                 for x in HDBSCAN_model.labels_]\n",
    "clusters_member_colors = [sns.desaturate(x, p) for x, p in\n",
    "                         zip(clusters_colors, HDBSCAN_model.probabilities_)]\n",
    "plt.scatter(AD6['LONG'], AD6['LAT'], s=50, linewidth=0, c=clusters_member_colors, alpha=1)\n",
    "plt.savefig('AD6_HDBSCAN_size1200_sample20.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meanshift\n",
    "#define the dataset\n",
    "X = np.array(list(zip(AD6['D20190125'],AD6['D20200131'])))\n",
    "# define the model\n",
    "Mean_model = MeanShift()\n",
    "# fit model and predict clusters\n",
    "yhat = Mean_model.fit_predict(X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# All the program statements\n",
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "\n",
    "print(\"Program Executed in \"+str(execution_time)) # It returns time in seconds\n",
    "\n",
    "#map the labels to colors\n",
    "c= ['b', 'r', 'y', 'g', 'c', 'm', 'e','f', 'u', 'd', 'a', 'h']\n",
    "colors = [c[i] for i in yhat]\n",
    "\n",
    "#Plot clusters with coordinates\n",
    "figure(num=None, figsize=(10, 8), dpi=100, facecolor='w', edgecolor='k')\n",
    "pyplot.scatter(AD6['LONG'], AD6['LAT'], c=yhat, s=10, cmap='viridis')\n",
    "plt.savefig('AD6_MEANSHIFT.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MiniBatch_Kmeans\n",
    "# define dataset\n",
    "X = np.array(list(zip(AD6['D20190125'],AD6['D20200131'])))\n",
    "# define the model\n",
    "MiniBatch_model = MiniBatchKMeans(n_clusters=6)\n",
    "# fit the model\n",
    "MiniBatch_model.fit(X)\n",
    "# assign a cluster to each example\n",
    "yhat = MiniBatch_model.predict(X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "\n",
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# All the program statements\n",
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "\n",
    "print(\"Program Executed in \"+str(execution_time)) # It returns time in seconds\n",
    "\n",
    "#map the labels to colors\n",
    "c= ['b', 'r', 'y', 'g', 'c', 'm', 'e','f', 'u', 'd', 'a', 'h']\n",
    "colors = [c[i] for i in yhat]\n",
    "\n",
    "#Plot clusters with coordinates\n",
    "figure(num=None, figsize=(10, 8), dpi=100, facecolor='w', edgecolor='k')\n",
    "pyplot.scatter(AD6['LONG'], AD6['LAT'], c=yhat, s=10, cmap='viridis')\n",
    "plt.savefig('AD6_MINIBATCH_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTICS\n",
    "# define dataset\n",
    "X = np.array(list(zip(AD6['D20190125'],AD6['D20200131'])))\n",
    "# define the model\n",
    "OPTICS_model = OPTICS(eps=5, min_samples=2)\n",
    "# fit model and predict clusters\n",
    "yhat = OPTICS_model.fit_predict(X)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# All the program statements\n",
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start\n",
    "\n",
    "print(\"Program Executed in \"+str(execution_time)) # It returns time in seconds\n",
    "\n",
    "#Plot clusters with coordinates\n",
    "figure(num=None, figsize=(9, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.scatter(AD6['LONG'], AD6['LAT'], c=yhat, s=10, cmap='plasma')\n",
    "pyplot.xlabel(\"LAT\")\n",
    "pyplot.ylabel(\"LONG\")\n",
    "plt.savefig('AD6_OPTICS_eps5_minsam2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Outputs and Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmeans\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "labels = kmeans_model.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in clusters:\n",
    "\t# get row indexes for samples with this cluster\n",
    "\trow_ix = where(yhat == cluster)\n",
    "\t# create scatter of these samples\n",
    "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels, metric='sqeuclidean'))\n",
    "#Calinski-Harabasz Index\n",
    "print(\"Calinski Harabasz Score: %0.3f\"\n",
    "      % metrics.calinski_harabasz_score(X, labels))\n",
    "#Davies Bouldin Index\n",
    "print(\"Davies Bouldin Index: %0.3f\"\n",
    "      % metrics.davies_bouldin_score(X, labels))\n",
    "\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = AD6.index.values\n",
    "cluster_map['cluster'] = kmeans_model.labels_\n",
    "\n",
    "cluster_map[cluster_map.cluster == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agglomerative\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "labels = AGGLO_model.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in clusters:\n",
    "\t# get row indexes for samples with this cluster\n",
    "\trow_ix = where(yhat == cluster)\n",
    "\t# create scatter of these samples\n",
    "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels, metric='sqeuclidean'))\n",
    "#Calinski-Harabasz Index\n",
    "print(\"Calinski Harabasz Score: %0.3f\"\n",
    "      % metrics.calinski_harabasz_score(X, labels))\n",
    "#Davies Bouldin Index\n",
    "print(\"Davies Bouldin Index: %0.3f\"\n",
    "      % metrics.davies_bouldin_score(X, labels))\n",
    "\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = AD6.index.values\n",
    "cluster_map['cluster'] = AGGLO_model.labels_\n",
    "\n",
    "cluster_map[cluster_map.cluster == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIRCH\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "labels = Birch_model.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in clusters:\n",
    "\t# get row indexes for samples with this cluster\n",
    "\trow_ix = where(yhat == cluster)\n",
    "\t# create scatter of these samples\n",
    "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels, metric='sqeuclidean'))\n",
    "#Calinski-Harabasz Index\n",
    "print(\"Calinski Harabasz Score: %0.3f\"\n",
    "      % metrics.calinski_harabasz_score(X, labels))\n",
    "#Davies Bouldin Index\n",
    "print(\"Davies Bouldin Index: %0.3f\"\n",
    "      % metrics.davies_bouldin_score(X, labels))\n",
    "\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = AD6.index.values\n",
    "cluster_map['cluster'] = Birch_model.labels_\n",
    "\n",
    "cluster_map[cluster_map.cluster == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN\n",
    "labels = DBSCAN_model.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "#metrics\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels, metric='sqeuclidean'))\n",
    "#Calinski-Harabasz Index\n",
    "print(\"Calinski Harabasz Score: %0.3f\"\n",
    "      % metrics.calinski_harabasz_score(X, labels))\n",
    "#Davies Bouldin Index\n",
    "print(\"Davies Bouldin Index: %0.3f\"\n",
    "      % metrics.davies_bouldin_score(X, labels))\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = AD6.index.values\n",
    "cluster_map['cluster'] = DBSCAN_model.labels_\n",
    "\n",
    "cluster_map[cluster_map.cluster == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GMM\n",
    "GMM_model.score\n",
    "GMM_model.aic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HDBSCAN\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "labels = HDBSCAN_model.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels, metric='sqeuclidean'))\n",
    "#Calinski-Harabasz Index\n",
    "print(\"Calinski Harabasz Score: %0.3f\"\n",
    "      % metrics.calinski_harabasz_score(X, labels))\n",
    "#Davies Bouldin Index\n",
    "print(\"Davies Bouldin Index: %0.3f\"\n",
    "      % metrics.davies_bouldin_score(X, labels))\n",
    "\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = AD6.index.values\n",
    "cluster_map['cluster'] = HDBSCAN_model.labels_\n",
    "\n",
    "cluster_map[cluster_map.cluster == 4]\n",
    "\n",
    "HDBSCAN_model.single_linkage_tree_.plot(cmap='viridis', colorbar=True)\n",
    "\n",
    "HDBSCAN_model.condensed_tree_.plot()\n",
    "\n",
    "HDBSCAN_model.condensed_tree_.plot(select_clusters=True, selection_palette=sns.color_palette())\n",
    "\n",
    "#The hdbscan library implements soft clustering, where each data point is assigned a cluster membership score ranging from 0.0 to 1.0. A score of 0.0 represents a sample that is not in the cluster at all (all noise points will get this score) while a score of 1.0 represents a sample that is at the heart of the cluster (note that this is not the spatial centroid notion of core). You can access these scores via the probabilities_ attribute.\n",
    "HDBSCAN_model.probabilities_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meanshift\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "labels = Mean_model.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels, metric='sqeuclidean'))\n",
    "#Calinski-Harabasz Index\n",
    "print(\"Calinski Harabasz Score: %0.3f\"\n",
    "      % metrics.calinski_harabasz_score(X, labels))\n",
    "#Davies Bouldin Index\n",
    "print(\"Davies Bouldin Index: %0.3f\"\n",
    "      % metrics.davies_bouldin_score(X, labels))\n",
    "\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = AD6.index.values\n",
    "cluster_map['cluster'] = Mean_model.labels_\n",
    "\n",
    "cluster_map[cluster_map.cluster == 4]\n",
    "\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in clusters:\n",
    "\t# get row indexes for samples with this cluster\n",
    "\trow_ix = where(yhat == cluster)\n",
    "\t# create scatter of these samples\n",
    "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MINIBATCH kmeans\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "labels = MiniBatch_model.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels, metric='sqeuclidean'))\n",
    "#Calinski-Harabasz Index\n",
    "print(\"Calinski Harabasz Score: %0.3f\"\n",
    "      % metrics.calinski_harabasz_score(X, labels))\n",
    "#Davies Bouldin Index\n",
    "print(\"Davies Bouldin Index: %0.3f\"\n",
    "      % metrics.davies_bouldin_score(X, labels))\n",
    "\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = AD6.index.values\n",
    "cluster_map['cluster'] = MiniBatch_model.labels_\n",
    "\n",
    "cluster_map[cluster_map.cluster == 4]\n",
    "\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in clusters:\n",
    "\t# get row indexes for samples with this cluster\n",
    "\trow_ix = where(yhat == cluster)\n",
    "\t# create scatter of these samples\n",
    "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTICS\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "labels = OPTICS_model.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels, metric='sqeuclidean'))\n",
    "#Calinski-Harabasz Index\n",
    "print(\"Calinski Harabasz Score: %0.3f\"\n",
    "      % metrics.calinski_harabasz_score(X, labels))\n",
    "#Davies Bouldin Index\n",
    "print(\"Davies Bouldin Index: %0.3f\"\n",
    "      % metrics.davies_bouldin_score(X, labels))\n",
    "\n",
    "cluster_map = pd.DataFrame()\n",
    "cluster_map['data_index'] = AD6.index.values\n",
    "cluster_map['cluster'] = OPTICS_model.labels_\n",
    "\n",
    "cluster_map[cluster_map.cluster == 600]\n",
    "\n",
    "# create scatter plot for samples from each cluster\n",
    "for cluster in clusters:\n",
    "\t# get row indexes for samples with this cluster\n",
    "\trow_ix = where(yhat == cluster)\n",
    "\t# create scatter of these samples\n",
    "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
